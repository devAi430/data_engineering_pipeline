
ðŸ“Œ devAi430 Data ETL Pipeline with Airflow, Python, and PostgreSQL

ðŸ”¹ Overview

This project demonstrates a complete ETL (Extract, Transform, Load) pipeline using Apache Airflow and Python.
The pipeline extracts data from CSV files, applies transformations, and loads the processed data into a PostgreSQL database.

It is designed to showcase fundamental data engineering skills, including data pipelines, orchestration, and testing.


---

ðŸ“‚ Project Structure

ETL_AIRFLOW_PROJECT/
 â”œâ”€â”€ dags/
 â”‚   â”œâ”€â”€ etl_pipeline.py       # Main Airflow DAG for ETL
 â”‚   â””â”€â”€ testdag.py            # Sample/Test DAG
 â”œâ”€â”€ data/
 â”‚   â”œâ”€â”€ db.sqlite             # PostgreSQL database
 â”‚   â”œâ”€â”€ extract.csv           # Extracted raw data
 â”‚   â”œâ”€â”€ source.csv            # Source data file
 â”‚   â””â”€â”€ transform.csv         # Transformed data
 â”œâ”€â”€ test/
 â”‚   â”œâ”€â”€ employees_clean.csv   # Cleaned employee dataset (for testing)
 â”‚   â”œâ”€â”€ test_etl.py           # Unit tests for ETL pipeline
 â”‚   â””â”€â”€ testsqlite.py         # Database connection tests
 â””â”€â”€ README.md                 # Project documentation


---

ðŸš€ Features

Extract data from CSV files

Transform data (cleaning & formatting)

Load data into PostgreSQL database

Airflow DAGs to orchestrate the pipeline

Unit tests for pipeline and database validation



---

âš™ Technologies Used

Python 3

Apache Airflow

PostgreSQL

CSV (pandas for handling data)


